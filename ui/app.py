"""
Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ì œê³µ
"""

import os
import sys
import streamlit as st
import pandas as pd
from datetime import datetime
import tempfile

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì„ ë§¨ ìœ„ë¡œ ì´ë™
os.environ['PYTORCH_JIT'] = '0'
if 'TOKENIZERS_PARALLELISM' not in os.environ:
    os.environ['TOKENIZERS_PARALLELISM'] = 'false'
os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ì„í¬íŠ¸ ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# íŒ¨ì¹˜ ë¨¼ì € ì ìš©
try:
    # ì˜¤í”„ë¼ì¸ ëª¨ë“œ ê´€ë ¨ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
    os.environ['HF_HUB_OFFLINE'] = '1'
    os.environ['TRANSFORMERS_OFFLINE'] = '1'
    os.environ['HF_DATASETS_OFFLINE'] = '1'
    
    from patches.apply_patches import setup_pytorch_environment, apply_huggingface_hub_patch, apply_sentence_transformers_patch, enable_offline_mode
    
    # ëª¨ë“  íŒ¨ì¹˜ ì ìš©
    enable_offline_mode()
    setup_pytorch_environment()
    apply_huggingface_hub_patch()
    apply_sentence_transformers_patch()  # í•­ìƒ ìŠ¤í… íŒ¨ì¹˜ ì ìš©
    
except ImportError:
    st.warning("íŒ¨ì¹˜ ëª¨ë“ˆì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

# huggingface_hub.constants íŒ¨ì¹˜ - sentence-transformers í˜¸í™˜ì„±ì„ ìœ„í•¨
try:
    import huggingface_hub.constants
    if not hasattr(huggingface_hub.constants, 'HF_HUB_DISABLE_TELEMETRY'):
        huggingface_hub.constants.HF_HUB_DISABLE_TELEMETRY = "HF_HUB_DISABLE_TELEMETRY"
    # ì¶”ê°€ì ì¸ ëˆ„ë½ëœ ìƒìˆ˜ë“¤ì— ëŒ€í•œ íŒ¨ì¹˜
    for const_name in ["HF_HUB_OFFLINE", "HF_DATASETS_OFFLINE", "HUGGINGFACE_HUB_CACHE", "HUGGINGFACE_ASSETS_CACHE"]:
        if not hasattr(huggingface_hub.constants, const_name):
            setattr(huggingface_hub.constants, const_name, const_name)
except (ImportError, AttributeError) as e:
    st.warning(f"huggingface_hub.constants íŒ¨ì¹˜ ì˜¤ë¥˜: {e}")

# PyTorch í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì„¤ì •
try:
    import torch
    if hasattr(torch, '_C'):
        try:
            torch._C._jit_set_profiling_executor(False)
            torch._C._jit_set_profiling_mode(False)
        except Exception as e:
            st.warning(f"PyTorch JIT ì„¤ì • ê²½ê³ : {e}")
except ImportError:
    pass

# huggingface_hub í˜¸í™˜ì„± ì²˜ë¦¬
try:
    import huggingface_hub
    if not hasattr(huggingface_hub, 'cached_download'):
        try:
            # ìµœì‹  ë²„ì „ì˜ ê²½ìš° hf_hub_download í•¨ìˆ˜ ì‚¬ìš©
            from huggingface_hub import hf_hub_download
            def cached_download_wrapper(*args, **kwargs):
                # cached_download -> hf_hub_download ëŒ€ì²´ ë˜í¼
                if 'cache_dir' in kwargs and 'local_dir' not in kwargs:
                    kwargs['local_dir'] = kwargs.pop('cache_dir')
                if 'force_download' in kwargs and 'force_download' not in kwargs:
                    kwargs['force_download'] = kwargs.pop('force_download')
                return hf_hub_download(*args, **kwargs)
            
            huggingface_hub.cached_download = cached_download_wrapper
        except ImportError:
            try:
                from huggingface_hub.utils import cached_download as cached_download_util
                huggingface_hub.cached_download = cached_download_util
            except ImportError:
                try:
                    from huggingface_hub.file_download import cached_download as cached_download_util
                    huggingface_hub.cached_download = cached_download_util
                except ImportError:
                    st.warning("huggingface_hub í˜¸í™˜ì„± íŒ¨ì¹˜ ì ìš© ì‹¤íŒ¨")
except ImportError as e:
    st.warning(f"huggingface_hub ê°€ì ¸ì˜¤ê¸° ê²½ê³ : {e}")

try:
    from processor.document_processor import process_document
    from embedding.embedder import create_embeddings, build_vector_db, load_vector_db
    from engine.rag_engine import process_rag, generate_testcases
    from validator.validator import validate_testcases
    from excel_exporter.excel_exporter import export_to_excel, export_validation_results, export_to_bytes
except Exception as e:
    st.error(f"ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
    st.stop()

# ì•± ì„¤ì •
st.set_page_config(
    page_title="ìë™ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±ê¸°",
    page_icon="ğŸ“‹",
    layout="wide"
)

def main():
    """Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ì¸ í•¨ìˆ˜"""
    
    st.title("ğŸ“‹ ìë™ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±ê¸°")
    st.write("ê¸°íšì„œ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°” - ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ì²­í¬ í¬ê¸° ì„¤ì •
        chunk_size = st.slider(
            "ì²­í¬ í¬ê¸°", 
            min_value=500, 
            max_value=2000, 
            value=1000, 
            step=100,
            help="ë¬¸ì„œë¥¼ ë¶„í• í•  ì²­í¬ì˜ í¬ê¸°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
        )
        
        # ì²­í¬ ì˜¤ë²„ë© ì„¤ì •
        chunk_overlap = st.slider(
            "ì²­í¬ ì˜¤ë²„ë©", 
            min_value=0, 
            max_value=500, 
            value=200, 
            step=50,
            help="ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ì •ë„ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
        )
        
        # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
        n_results = st.slider(
            "ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 
            min_value=3, 
            max_value=10, 
            value=5, 
            step=1,
            help="RAG ê²€ìƒ‰ ì‹œ ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
        )
        
        # ë²¡í„° DB ë””ë ‰í† ë¦¬
        vector_db_dir = st.text_input(
            "ë²¡í„° DB ë””ë ‰í† ë¦¬",
            value="data/embeddings",
            help="ë²¡í„° DBë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ ì§€ì •í•©ë‹ˆë‹¤."
        )
        
        st.divider()
        
        # í”„ë¡œì„¸ìŠ¤ ì •ë³´
        st.header("â„¹ï¸ í”„ë¡œì„¸ìŠ¤ ì •ë³´")
        st.info(
            "1. ë¬¸ì„œ ì—…ë¡œë“œ: DOCX ë˜ëŠ” PDF ê¸°íšì„œë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤.\n"
            "2. ë°ì´í„° ì²˜ë¦¬: ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•˜ê³  ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.\n"
            "3. ì„ë² ë”© ìƒì„±: í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n"
            "4. í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±: RAG ë°©ì‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n"
            "5. ê²€ì¦ ë° í”¼ë“œë°±: ìƒì„±ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ê²€ì¦í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.\n"
            "6. ì—‘ì…€ ë‚´ë³´ë‚´ê¸°: ìµœì¢… ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."
        )
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'document_processed' not in st.session_state:
        st.session_state.document_processed = False
    if 'testcases_generated' not in st.session_state:
        st.session_state.testcases_generated = False
    
    # ë©”ì¸ ì˜ì—­ - íƒ­ êµ¬ì„±
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ", "ğŸ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±", "ğŸ“Š ê²°ê³¼ í™•ì¸"])
    
    # íƒ­1: ë¬¸ì„œ ì—…ë¡œë“œ
    with tab1:
        st.header("ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ")
        
        uploaded_file = st.file_uploader(
            "DOCX ë˜ëŠ” PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", 
            type=["docx", "pdf"]
        )
        
        if uploaded_file is not None:
            try:
                # ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
                if not os.path.exists("data"):
                    os.makedirs("data", exist_ok=True)
                
                # ê³ ì • ì„ì‹œ íŒŒì¼ ê²½ë¡œ ì‚¬ìš© (ë””ë²„ê¹…ìš©)
                fixed_temp_dir = os.path.join(os.path.abspath("data"), "temp")
                os.makedirs(fixed_temp_dir, exist_ok=True)
                
                # íŒŒì¼ í™•ì¥ì í™•ì¸
                file_ext = os.path.splitext(uploaded_file.name)[1]
                st.write(f"íŒŒì¼ í˜•ì‹: {file_ext}")
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                temp_file_path = os.path.join(fixed_temp_dir, f"uploaded{file_ext}")
                with open(temp_file_path, "wb") as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                
                st.write(f"ì„ì‹œ íŒŒì¼ ì €ì¥ë¨: {temp_file_path}")
                st.write(f"íŒŒì¼ í¬ê¸°: {os.path.getsize(temp_file_path)} ë°”ì´íŠ¸")
                
                st.success(f"'{uploaded_file.name}' íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            except Exception as upload_error:
                st.error(f"íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ ì˜¤ë¥˜: {upload_error}")
                import traceback
                st.code(traceback.format_exc())
            
            # ì„¸ì…˜ ìƒíƒœì— íŒŒì¼ ê²½ë¡œ ì €ì¥
            st.session_state.uploaded_file_path = temp_file_path
            st.session_state.uploaded_file_name = uploaded_file.name
            
            # ì²˜ë¦¬ ë²„íŠ¼
            if st.button("ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘", type="primary"):
                try:
                    with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        # 1. ë¬¸ì„œ ì²˜ë¦¬
                        st.info("1/4 ë‹¨ê³„: ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•˜ê³  ì²­í¬ë¡œ ë¶„í•  ì¤‘...")
                        try:
                            # ë””ë²„ê¹…ì„ ìœ„í•œ ì •ë³´ ì¶œë ¥
                            st.write(f"íŒŒì¼ ê²½ë¡œ: {st.session_state.uploaded_file_path}")
                            st.write(f"íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(st.session_state.uploaded_file_path)}")
                            
                            chunks = process_document(
                                st.session_state.uploaded_file_path, 
                                chunk_size=chunk_size, 
                                chunk_overlap=chunk_overlap
                            )
                            st.write(f"ì²˜ë¦¬ëœ ì²­í¬ ìˆ˜: {len(chunks)}")
                        except Exception as doc_error:
                            st.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì˜¤ë¥˜: {doc_error}")
                            import traceback
                            st.code(traceback.format_exc())
                            raise
                        
                        # 2. ì„ë² ë”© ìƒì„±
                        st.info("2/4 ë‹¨ê³„: í…ìŠ¤íŠ¸ ì²­í¬ ì„ë² ë”© ìƒì„± ì¤‘...")
                        try:
                            embedded_chunks = create_embeddings(chunks)
                            st.write(f"ì„ë² ë”©ëœ ì²­í¬ ìˆ˜: {len(embedded_chunks)}")
                        except Exception as emb_error:
                            st.error(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {emb_error}")
                            import traceback
                            st.code(traceback.format_exc())
                            raise
                        
                        # 3. ë²¡í„° DB êµ¬ì¶•
                        st.info("3/4 ë‹¨ê³„: ë²¡í„° DB êµ¬ì¶• ì¤‘...")
                        try:
                            vector_db = build_vector_db(embedded_chunks, vector_db_dir)
                            st.write(f"ë²¡í„° DB ë””ë ‰í† ë¦¬: {vector_db_dir}")
                        except Exception as db_error:
                            st.error(f"ë²¡í„° DB êµ¬ì¶• ì˜¤ë¥˜: {db_error}")
                            import traceback
                            st.code(traceback.format_exc())
                            raise
                        
                        # 4. ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥
                        original_text = "\n".join([chunk['text'] for chunk in chunks])
                        
                        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                        st.session_state.chunks = chunks
                        st.session_state.embedded_chunks = embedded_chunks
                        st.session_state.vector_db = vector_db
                        st.session_state.vector_db_dir = vector_db_dir
                        st.session_state.original_text = original_text
                        st.session_state.document_processed = True
                        
                        st.success("ë¬¸ì„œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! 'í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
                except Exception as e:
                    st.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    # íƒ­2: í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±
    with tab2:
        st.header("ğŸ” í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±")
        
        if not st.session_state.get("document_processed", False):
            st.warning("ë¨¼ì € 'ë¬¸ì„œ ì—…ë¡œë“œ' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        else:
            st.info(f"ì²˜ë¦¬ëœ ë¬¸ì„œ: {st.session_state.uploaded_file_name}")
            
            # ì¿¼ë¦¬ ì…ë ¥ (ì„ íƒì‚¬í•­)
            query = st.text_input(
                "íŠ¹ì • ë¶€ë¶„ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•˜ë ¤ë©´ ì—¬ê¸°ì— ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­)",
                help="ë¹„ì›Œë‘ë©´ ì „ì²´ ë¬¸ì„œì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ê°€ ìƒì„±ë©ë‹ˆë‹¤."
            )
            
            # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ë²„íŠ¼
            if st.button("í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±", type="primary"):
                try:
                    with st.spinner("í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        # ë²¡í„° DBê°€ ì„¸ì…˜ì— ì—†ë‹¤ë©´ ë¡œë“œ
                        if 'vector_db' not in st.session_state:
                            vector_db = load_vector_db(st.session_state.vector_db_dir)
                            st.session_state.vector_db = vector_db
                        
                        if query:
                            # ì¿¼ë¦¬ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±
                            st.info("ì¿¼ë¦¬ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ì¤‘...")
                            testcases = process_rag(
                                st.session_state.vector_db, 
                                query,
                                n_results=n_results
                            )
                        else:
                            # ì „ì²´ ë¬¸ì„œ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±
                            st.info("ì „ì²´ ë¬¸ì„œ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ì¤‘...")
                            testcases = generate_testcases(
                                st.session_state.vector_db, 
                                st.session_state.chunks
                            )
                        
                        # ê²€ì¦ ì ˆì°¨
                        st.info("ìƒì„±ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê²€ì¦ ì¤‘...")
                        validation_results = validate_testcases(
                            testcases, 
                            st.session_state.original_text
                        )
                        
                        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                        st.session_state.testcases = testcases
                        st.session_state.validation_results = validation_results
                        st.session_state.testcases_generated = True
                        
                        st.success("í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! 'ê²°ê³¼ í™•ì¸' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")
                except Exception as e:
                    st.error(f"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    # íƒ­3: ê²°ê³¼ í™•ì¸
    with tab3:
        st.header("ğŸ“Š ê²°ê³¼ í™•ì¸")
        
        if not st.session_state.get("testcases_generated", False):
            st.warning("ë¨¼ì € 'í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ìƒì„±' íƒ­ì—ì„œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        else:
            try:
                # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ í…Œì´ë¸” í‘œì‹œ
                st.subheader("ìƒì„±ëœ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤")
                
                # DataFrame ìƒì„±
                testcases_df = pd.DataFrame(st.session_state.testcases)
                
                # í•„ìˆ˜ ì»¬ëŸ¼ ì¶”ê°€
                required_columns = ["ëŒ€ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "í™•ì¸ë‚´ìš©", "ê²°ê³¼", "JIRA", "AD", "iOS", "PC", "ë¹„ê³ "]
                for col in required_columns:
                    if col not in testcases_df.columns:
                        testcases_df[col] = ""
                
                # ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬
                testcases_df = testcases_df[required_columns]
                
                # í…Œì´ë¸” í‘œì‹œ
                st.dataframe(testcases_df, use_container_width=True)
                
                # í†µê³„ ì •ë³´ í‘œì‹œ
                st.subheader("QA T/C ì´ í˜„í™©")
                total_count = len(testcases_df)
                pass_count = sum(1 for _, row in testcases_df.iterrows() 
                                if row.get('AD') == 'PASS' or row.get('iOS') == 'PASS' or row.get('PC') == 'PASS')
                fail_count = sum(1 for _, row in testcases_df.iterrows() 
                                if row.get('AD') == 'FAIL' or row.get('iOS') == 'FAIL' or row.get('PC') == 'FAIL')
                not_tested_count = total_count - pass_count - fail_count
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("í…ŒìŠ¤íŠ¸ ì „", not_tested_count)
                with col2:
                    st.metric("í†µê³¼", pass_count)
                with col3:
                    st.metric("ì‹¤íŒ¨", fail_count)
                with col4:
                    st.metric("ì „ì²´ ê°œìˆ˜", total_count)
                
                # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
                st.subheader("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
                
                # Excel íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                excel_filename = f"í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤_{timestamp}.xlsx"
                
                try:
                    # excel_exporterì—ì„œ ë°”ì´íŠ¸ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
                    excel_bytes = export_to_bytes(st.session_state.testcases)
                    
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    st.download_button(
                        label="ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=excel_bytes,
                        file_name=excel_filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except Exception as excel_error:
                    st.error(f"ì—‘ì…€ ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {excel_error}")
                    import traceback
                    st.code(traceback.format_exc())
            except Exception as e:
                st.error(f"ê²°ê³¼ í‘œì‹œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                if st.button("ì„¸ì…˜ ì´ˆê¸°í™”"):
                    for key in list(st.session_state.keys()):
                        del st.session_state[key]
                    st.experimental_rerun()

if __name__ == "__main__":
    main()